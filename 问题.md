一、数据增强：
随机选择、平移、缩放、裁剪、左右翻转
对图像中的像素添加噪声扰动，如高斯白噪声
颜色变化
改变图像的亮度、清晰度、对比度、锐化等

二、归一化
将一个变量的取值缩放到[0~1]之间

1、L1归一化：将每个数据除以L1范数(所有数据的绝对值之和)
线性回归、逻辑回归、SVM、神经网络需要做归一化，这些模型都带有类似​ 形式的计算

2、线性归一化：(x-xmin)/(xmax-xmin)
决策树不需要归一化，关注的是信息增益比。

标准化：将一个特征变成标准的 01高斯分布
  
  ![](https://github.com/xingcongying/ML/blob/main/images/QQ%E5%9B%BE%E7%89%8720220225154159.png)
 为什么进行归一化：
两个原因：第一是可以加速梯度下降法的梯度迭代收敛速度。以两个特征为例，如果两个特征不在一个量纲，则他们的损失等高线则是一个椭圆形，而经过归一化后，损失等高曲线则是一个圆形，以同样的学习率进行梯度下降时，椭圆型会走之字形，收敛速度慢，而原型的收敛速度快。

第二原因：可能提高精度。在某些运用到距离的算法中，比如KNN，需要计算特征与特征之间的距离，如果某个特征的量纲很大，某个特征的量纲很小，则他们之间的距离就会由大值特征决定，如果小值特征才是对结果具有更加有意义的特征的话，这个时候可能就会损失精度。

为什么进行标准化？标准化的目的是为了使得数据是同一分布，而神经网络就是为了学习输入数据得这种分布，如果每次得输入都不是一个分布，则网络就会花费大量的时间，所以标准化也可以是为了提高收敛速度。

补充，思考一个问题：决策树是否需要归一化？

答案是不需要。决策树的构建是通过特征选择来进行得，而特征选择的标准比如信息增益 基尼系数这些都是统计量而不是数值上的计算，因此不许用进行归一化。同时，归一化是为了加快梯度收敛，而决策树没有梯度的概念，决策树是一个阶跃式的模型，在分裂点处（相当于LR的变量w）没有梯度的概念。
