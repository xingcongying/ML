一、决策树
ID3，C4.5和CART树

决策树呈树形结构，在分类问题中，表示基于特征对实例进行分类的过程。学习时，利用训练数据，根据损失函数最小化的原则建立决策树模型；预测时，对新的数据，利用决策模型进行分类。

决策树的分类：离散性决策树、连续性决策树。

离散性决策树：离散性决策树，其目标变量是离散的，如性别：男或女等；

连续性决策树：连续性决策树，其目标变量是连续的，如工资、价格、年龄等；

决策树的优点：（1）具有可读性，如果给定一个模型，那么过呢据所产生的决策树很容易推理出相应的逻辑表达。（2）分类速度快，能在相对短的时间内能够对大型数据源做出可行且效果良好的结果。

决策树的缺点：（1）对未知的测试数据未必有好的分类、泛化能力，即可能发生过拟合现象，此时可采用剪枝或随机森林。

①ID3 ---- ID3算法最核心的思想是采用信息增益来选择特征

②C4.5采用信息增益比，用于减少ID3算法的局限（在训练集中，某个属性所取的不同值的个数越多，那么越有可能拿它来作为分裂属性，而这样做有时候是没有意义的）

③CART算法采用gini系数，不仅可以用来分类，也可以解决回归问题。
